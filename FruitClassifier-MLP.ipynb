{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21e2a59-026c-4193-a3b4-57ba3ec6ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   fruit_label fruit_name fruit_subtype   mass  width  height  color_score\n",
      "0            1      apple  granny_smith  192.0    8.4     7.3         0.55\n",
      "1            1      apple  granny_smith  180.0    8.0     6.8         0.59\n",
      "2            1      apple  granny_smith  176.0    7.4     7.2         0.60\n",
      "3            2   mandarin      mandarin   86.0    6.2     4.7         0.80\n",
      "4            2   mandarin      mandarin   84.0    6.0     4.6         0.79\n",
      "Test Accuracy: 0.9667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.98      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the fruit dataset\n",
    "file_path = 'AI PROJECT.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "# Using 'mass', 'width', 'height', 'color_score' as features and 'fruit_label' as the target\n",
    "X = df[['mass', 'width', 'height', 'color_score']]\n",
    "y = df['fruit_label']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build and train the MLP model\n",
    "model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c6b3c4d-cff5-4e57-93c5-3994dc2bb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.3832\n",
      "Epoch 100, Loss: 1.2554\n",
      "Epoch 200, Loss: 1.2235\n",
      "Epoch 300, Loss: 1.1739\n",
      "Epoch 400, Loss: 1.0753\n",
      "Epoch 500, Loss: 0.8994\n",
      "Epoch 600, Loss: 0.7458\n",
      "Epoch 700, Loss: 0.6519\n",
      "Epoch 800, Loss: 0.5899\n",
      "Epoch 900, Loss: 0.5450\n",
      "Test Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "#NEURAL NETWORK\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'AI PROJECT.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[['mass', 'width', 'height', 'color_score']]\n",
    "y = df['fruit_label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Neural Network class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.bias_hidden = np.zeros((1, hidden_size))\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.bias_output = np.zeros((1, output_size))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.hidden_layer_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
    "\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = self.softmax(self.output_layer_input)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, X, Y, learning_rate):\n",
    "        output_error = self.output - Y\n",
    "        output_gradient = output_error / X.shape[0]\n",
    "        hidden_error = np.dot(output_gradient, self.weights_hidden_output.T) * self.sigmoid_derivative(self.hidden_layer_output)\n",
    "        self.weights_hidden_output -= learning_rate * np.dot(self.hidden_layer_output.T, output_gradient)\n",
    "        self.bias_output -= learning_rate * np.sum(output_gradient, axis=0, keepdims=True)\n",
    "\n",
    "        self.weights_input_hidden -= learning_rate * np.dot(X.T, hidden_error)\n",
    "        self.bias_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, X, Y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(X, Y, learning_rate)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = -np.sum(Y * np.log(self.output)) / X.shape[0]\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.forward(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_one_hot = np.eye(len(np.unique(y)))[y_train - 1]  \n",
    "y_test_one_hot = np.eye(len(np.unique(y)))[y_test - 1]    \n",
    "\n",
    "# Initialize and train the neural network\n",
    "nn = NeuralNetwork(input_size=X_train.shape[1], hidden_size=8, output_size=len(np.unique(y)))\n",
    "nn.train(X_train, y_train_one_hot, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = nn.predict(X_test)\n",
    "accuracy = np.mean(y_pred == (y_test - 1))  \n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8425bd6c-7371-4ceb-9fae-b1725292a7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   fruit_label fruit_name fruit_subtype   mass  width  height  color_score\n",
      "0            1      apple  granny_smith  192.0    8.4     7.3         0.55\n",
      "1            1      apple  granny_smith  180.0    8.0     6.8         0.59\n",
      "2            1      apple  granny_smith  176.0    7.4     7.2         0.60\n",
      "3            2   mandarin      mandarin   86.0    6.2     4.7         0.80\n",
      "4            2   mandarin      mandarin   84.0    6.0     4.6         0.79\n",
      "\n",
      "Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "#KNN CLASSIFICATION\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the fruit dataset from the CSV file\n",
    "csv_file = 'AI PROJECT.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "# Using 'mass', 'width', 'height', 'color_score' as features and 'fruit_label' as the target\n",
    "X = df[['mass', 'width', 'height', 'color_score']]\n",
    "y = df['fruit_label']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train the KNN classifier\n",
    "# Setting n_neighbors=3 as an example (you can change this value)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_prediction = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_prediction)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a14e2ed3-5755-4c2e-b250-de0d4e208448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   fruit_label fruit_name fruit_subtype   mass  width  height  color_score\n",
      "0            1      apple  granny_smith  192.0    8.4     7.3         0.55\n",
      "1            1      apple  granny_smith  180.0    8.0     6.8         0.59\n",
      "2            1      apple  granny_smith  176.0    7.4     7.2         0.60\n",
      "3            2   mandarin      mandarin   86.0    6.2     4.7         0.80\n",
      "4            2   mandarin      mandarin   84.0    6.0     4.6         0.79\n",
      "test data accuracy :  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "#Gaussian\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn as sns\n",
    "\n",
    "csv_file = 'AI PROJECT.csv'\n",
    "\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "# Using 'mass', 'width', 'height', 'color_score' as features and 'fruit_label' as the target\n",
    "X = df[['mass', 'width', 'height', 'color_score']]\n",
    "y = df['fruit_label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#less neighbors more accuracy\n",
    "\n",
    "guassian= GaussianNB()\n",
    "\n",
    "GaussianNB()\n",
    "\n",
    "\n",
    "guassian.fit(X_train, y_train) # train the model\n",
    "\n",
    "y_prediction = guassian.score(X_test,y_test)\n",
    "\n",
    "print(\"test data accuracy : \",y_prediction)\n",
    "\n",
    "#acc = accuracy_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789b9e0-8442-4759-85b8-5028a08cd6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
